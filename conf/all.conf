#======================CEPH DEPLOY=======================
#ceph config path
conf_path="/etc/ceph/ceph.conf"
# username for all host
deploy_username=ceph
# monitor servers , splited by ','
deploy_mon_servers=osd1
# osds servers, splited by ','
#deploy_osd_servers=osd1,osd2,osd3,osd4
deploy_osd_servers=osd1,osd2,osd3,osd4
# mds servers, splited by ','
#deploy_mds_servers=aceph01
# rbd clients, split by ','
deploy_rbd_nodes=client01,client02,client03,client04
# osd-journal list , splited by ','
#aceph01=/dev/sdc1:/dev/sdi3,/dev/sde1:/dev/sdi4
# osd partition_count on one HDD, and the size( default will use the full disk )
osd_partition_count=1
osd_partition_size=1000G
# journal partition_count on one HDD, and the size
journal_partition_count=10
journal_partition_size=10G
#===================== VCLIENT ======================
list_vclient=vclient01,vclient02,vclient03,vclient04,vclient05,vclient06,vclient07,vclient08,vclient09,vclient10,vclient11,vclient12,vclient13,vclient14,vclient15,vclient16,vclient17,vclient18,vclient19,vclient20,vclient21,vclient22,vclient23,vclient24,vclient25,vclient26,vclient27,vclient28,vclient29,vclient30,vclient31,vclient32,vclient33,vclient34,vclient35,vclient36,vclient37,vclient38,vclient39,vclient40,vclient41,vclient42,vclient43,vclient44,vclient45,vclient46,vclient47,vclient48,vclient49,vclient50,vclient51,vclient52,vclient53,vclient54,vclient55,vclient56,vclient57,vclient58,vclient59,vclient60,vclient61,vclient62,vclient63,vclient64,vclient65,vclient66,vclient67,vclient68,vclient69,vclient70,vclient71,vclient72,vclient73,vclient74,vclient75,vclient76,vclient77,vclient78,vclient79,vclient80,vclient81,vclient82,vclient83,vclient84,vclient85,vclient86,vclient87,vclient88,vclient89,vclient90,vclient91,vclient92,vclient93,vclient94,vclient95,vclient96,vclient97,vclient98,vclient99,vclient100,vclient101,vclient102,vclient103,vclient104,vclient105,vclient106,vclient107,vclient108,vclient109,vclient110,vclient111,vclient112,vclient113,vclient114,vclient115,vclient116,vclient117,vclient118,vclient119,vclient120,vclient121,vclient122,vclient123,vclient124,vclient125,vclient126,vclient127,vclient128,vclient129,vclient130,vclient131,vclient132,vclient133,vclient134,vclient135,vclient136,vclient137,vclient138,vclient139,vclient140
#list_vclient=vclient01,vclient02,vclient03,vclient04,vclient05,vclient06,vclient07,vclient08,vclient09,vclient10,vclient11,vclient12,vclient13,vclient14,vclient15,vclient16,vclient17,vclient18,vclient19,vclient20,vclient21,vclient22,vclient23,vclient24,vclient25,vclient26,vclient27,vclient28,vclient29,vclient30,vclient31,vclient32,vclient33,vclient34,vclient35
# the cpu vm cpupin start with
cpuset_start=0
# the max num of vms in each hypervisor/node 
vm_num_per_client=35
# img_path_dir
img_path_dir=/mnt/images
# ip_prefix
ip_prefix=10.10.2
# ip_fix_start , vm will be created from ip_prefix.if_fix, example: if set ip_prefix = 192.168.9; ip_fix = 201, then the first vm ip will be 192.168.9.201, the second vm should be 192.168.9.202 and so on
ip_fix=101
vm_image_locate_server=10.239.158.45
#=====================BENCHMARK=====================
head=client01
fio_for_libcephfs_dir=/opt
tmp_dir=/opt
user=root
list_mon=osd1
list_client=client01,client02,client03,client04
list_ceph=osd1,osd2,osd3,osd4
list_nic=osd1:p513p1,osd2:p513p1,osd3:p513p1,osd4:p513p1
osd1=/dev/sdc1:/dev/sdb6,/dev/sdd1:/dev/sdb7,/dev/sde1:/dev/sdb8,/dev/sdf1:/dev/sdb9,/dev/sdg1:/dev/sdb10,/dev/sdi1:/dev/sdh6,/dev/sdj1:/dev/sdh7,/dev/sdk1:/dev/sdh8,/dev/sdl1:/dev/sdh9,/dev/sdm1:/dev/sdh10
osd2=/dev/sdc1:/dev/sdb6,/dev/sdd1:/dev/sdb7,/dev/sde1:/dev/sdb8,/dev/sdf1:/dev/sdb9,/dev/sdg1:/dev/sdb10,/dev/sdi1:/dev/sdh6,/dev/sdj1:/dev/sdh7,/dev/sdk1:/dev/sdh8,/dev/sdl1:/dev/sdh9,/dev/sdm1:/dev/sdh10
osd3=/dev/sdc1:/dev/sdb6,/dev/sdd1:/dev/sdb7,/dev/sde1:/dev/sdb8,/dev/sdf1:/dev/sdb9,/dev/sdg1:/dev/sdb10,/dev/sdi1:/dev/sdh6,/dev/sdj1:/dev/sdh7,/dev/sdk1:/dev/sdh8,/dev/sdl1:/dev/sdh9,/dev/sdm1:/dev/sdh10
osd4=/dev/sdc1:/dev/sdb6,/dev/sdd1:/dev/sdb7,/dev/sde1:/dev/sdb8,/dev/sdf1:/dev/sdb9,/dev/sdg1:/dev/sdb10,/dev/sdi1:/dev/sdh6,/dev/sdj1:/dev/sdh7,/dev/sdk1:/dev/sdh8,/dev/sdl1:/dev/sdh9,/dev/sdm1:/dev/sdh10
# rgw deployment config
rgw_server=RGW
monitor_network=192.168.2.0/24
rgw_start_index=1
rgw_num_per_server=5
volume_size=40960
benchmark_engine=qemurbd,cosbench
rbd_volume_count=140
fio_capping=true
# vm # , split by ','
run_vm_num=140
# disk , split by ','
run_file=/dev/vdb
# test size , split by ','
run_size=40g
# io pattern, split by ','
run_io_pattern=seqwrite,seqread,randwrite,randread
# record size, split by ','
run_record_size=64k,4k
# queue depth, split by ','
run_queue_depth=64,8
# warm-up time
run_warmup_time=0
# run time
run_time=400
# destination directory
dest_dir=/mnt/data/
# destination directory
dest_dir_remote_bak=192.168.3.101:/share/chendi_new/dp_setup/firefly_tuned/
# only used in fio_rbd engine test scenario
rbd_num_per_client=35,35,35,35
#====================RGW CONFIGURATION===================
# cosbench
cosbench_version=v0.4.2.c2
cosbench_controller=client01
cosbench_driver=client01,client02,client03,client04
cosbench_folder=/opt/cosbench
cosbench_config_dir=/opt/cosbench_config
cosbench_cluster_ip=10.10.2.22
cosbench_admin_ip=192.168.2.36
cosbench_network=192.168.2.0/24
cosbench_auth_username=cosbench:operator
cosbench_auth_password=intel2012
cosbench_controller_proxy=""
cosbench_workers=0,160,320
cosbench_test_size=128KB,10MB
cosbench_rw=read,write
cosbench_containers=r(1,100)
cosbench_objects=r(1,100)
#====================CEPH CONFIGURATION===================
[ceph_conf]
public_network = 10.10.2.0/24
cluster_network = 10.10.2.0/24
